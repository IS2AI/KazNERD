[Embed]
pretrained_embed = False
zeros = False
avg = False
uniform = False
nnembed = False
pretrained_embed_file = 

[Data]
train_file = ../KazNERD/IOB2_train.txt
dev_file = ../KazNERD/IOB2_valid.txt
test_file = ../KazNERD/IOB2_test.txt
max_count = -1
min_freq = 1
shuffle = True
epochs_shuffle = True

[Save]
save_pkl = False
pkl_directory = ./Save_pkl
pkl_data = pkl_data.pkl
pkl_alphabet = pkl_alphabet.pkl
pkl_iter = pkl_iter.pkl
pkl_embed = pkl_embed.pkl
save_dict = False
dict_directory = ./Save_dictionary
word_dict = dictionary_word.txt
label_dict = dictionary_label.txt
save_direction = ./Save_model
save_best_model_dir = ./Save_BModel
save_model = False
save_all_model = False
save_best_model = True
model_name = ner_model
rm_model = True

[Model]
average_batch = False
use_crf = True
use_char = True
model_bilstm = True
model_bilstm_context = False
embed_dim = 100
embed_finetune = True
lstm_layers = 1
lstm_hiddens = 256
dropout_emb = 0.5
dropout = 0.5
max_char_len = 20
char_dim = 30
conv_filter_sizes = 3
conv_filter_nums = 30
windows_size = 5

[Optimizer]
adam = True
sgd = False
learning_rate = 0.005
weight_decay = 1.0e-9
momentum = 0.0
clip_max_norm_use = False
clip_max_norm = None
use_lr_decay = False
lr_rate_decay = 0.05
min_lrate = 0.000005
max_patience = 1

[Train]
num_threads = 1
epochs = 1000
early_max_patience = 100
backward_batch_size = 1
batch_size = 1024
dev_batch_size = 10
test_batch_size = 10
log_interval = 20

